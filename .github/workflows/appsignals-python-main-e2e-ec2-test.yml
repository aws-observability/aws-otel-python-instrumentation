## Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
## SPDX-License-Identifier: Apache-2.0

# This is a reusable workflow for running the Python E2E test in Main build for App Signals.
# It is meant to be called from another workflow.
# Read more about reusable workflows: https://docs.github.com/en/actions/using-workflows/reusing-workflows#overview
name: App Signals Enablement E2E Testing - Python Main Build EC2 Use Case
on:
  workflow_call:
    inputs:
      aws-region:
        required: true
        type: string
      staging_wheel_name:
        required: true
        type: string
      caller-workflow-name:
        required: true
        type: string

permissions:
  id-token: write
  contents: read

env:
  # The precense of this env var is required for use by terraform and AWS CLI commands
  # It is not redundant
  AWS_DEFAULT_REGION: ${{ inputs.aws-region }}
  TEST_ACCOUNT: ${{ secrets.APP_SIGNALS_E2E_TEST_ACC }}
  SAMPLE_APP_ZIP: s3://${{ secrets.E2E_TEST_BUCKET }}-prod-${{ inputs.aws-region }}/python-sample-app.zip
  METRIC_NAMESPACE: AppSignals
  LOG_GROUP_NAME: /aws/appsignals/generic
  ADOT_WHEEL_NAME: ${{ inputs.staging_wheel_name }}


jobs:
  python-e2e-ec2-test:
    runs-on: ubuntu-latest
    steps:
      - name: Get testing resources from aws-application-signals-test-framework
        uses: actions/checkout@v4
        with:
          repository: aws-observability/aws-application-signals-test-framework
          ref: s3_us-east-1

      - name: Set CW Agent RPM environment variable
        run: echo GET_CW_AGENT_RPM_COMMAND="wget -O cw-agent.rpm https://amazoncloudwatch-agent-us-east-1.s3.amazonaws.com/amazon_linux/amd64/1.300031.0b313/amazon-cloudwatch-agent.rpm" >> $GITHUB_ENV

      - name: Generate testing id
        run: echo TESTING_ID="${{ github.run_id }}-${{ github.run_number }}" >> $GITHUB_ENV

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.E2E_SECRET_TEST_ROLE_ARN }}
          aws-region: us-east-1

      - name: Retrieve account
        uses: aws-actions/aws-secretsmanager-get-secrets@v1
        with:
          secret-ids:
            ACCOUNT_ID, region-account/${{ env.AWS_DEFAULT_REGION }}

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ env.ACCOUNT_ID }}:role/${{ secrets.E2E_TEST_ROLE_ARN }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}

      - uses: actions/download-artifact@v3
        if: inputs.caller-workflow-name == 'main-build'
        with:
          name: ${{ inputs.staging_wheel_name }}

      - name: Upload main-build adot.whl to s3
        run: aws s3 cp ${{ inputs.staging_wheel_name }} s3://adot-main-build-staging-jar/${{ env.ADOT_WHEEL_NAME }}

      - name: Set Get ADOT Wheel command environment variable
        working-directory: terraform/python/ec2
        run: |
          echo GET_ADOT_WHEEL_COMMAND="aws s3 cp s3://adot-main-build-staging-jar/${{ env.ADOT_WHEEL_NAME }} ./${{ env.ADOT_WHEEL_NAME }} && python3.9 -m pip install ${{ env.ADOT_WHEEL_NAME }}" >> $GITHUB_ENV


      - name: Set up terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Deploy sample app via terraform
        working-directory: terraform/python/ec2
        run: |
          terraform init
          terraform validate
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_DEFAULT_REGION }}" \
            -var="test_id=${{ env.TESTING_ID }}" \
            -var="sample_app_zip=${{ env.SAMPLE_APP_ZIP }}" \
            -var="get_cw_agent_rpm_command=${{ env.GET_CW_AGENT_RPM_COMMAND }}" \
            -var="get_adot_wheel_command=${{ env.GET_ADOT_WHEEL_COMMAND }}"

      - name: Get the ec2 instance ami id
        run: |
          echo "EC2_INSTANCE_AMI=$(terraform output ec2_instance_ami)" >> $GITHUB_ENV
        working-directory: terraform/python/ec2

      - name: Get the sample app endpoint
        run: |
          echo "MAIN_SERVICE_ENDPOINT=$(terraform output sample_app_main_service_public_dns):8000" >> $GITHUB_ENV
          echo "REMOTE_SERVICE_IP=$(terraform output sample_app_remote_service_public_ip)" >> $GITHUB_ENV
        working-directory: terraform/python/ec2

      - name: Wait for app endpoint to come online
        id: endpoint-check
        run: |
          attempt_counter=0
          max_attempts=30
          until $(curl --output /dev/null --silent --head --fail http://${{ env.MAIN_SERVICE_ENDPOINT }}); do
            if [ ${attempt_counter} -eq ${max_attempts} ];then
             echo "Max attempts reached"
             exit 1
            fi
          
            printf '.'
            attempt_counter=$(($attempt_counter+1))
            sleep 10
          done

      # This steps increases the speed of the validation by creating the telemetry data in advance
      - name: Call all test APIs
        continue-on-error: true
        run: |
          curl -S -s http://${{ env.MAIN_SERVICE_ENDPOINT }}/outgoing-http-call
          curl -S -s http://${{ env.MAIN_SERVICE_ENDPOINT }}/aws-sdk-call
          curl -S -s http://${{ env.MAIN_SERVICE_ENDPOINT }}/remote-service?ip=${{ env.REMOTE_SERVICE_IP }}
          curl -S -s http://${{ env.MAIN_SERVICE_ENDPOINT }}/client-call

      # Validation for pulse telemetry data
      - name: Validate generated EMF logs
        id: log-validation
        run: ./gradlew validator:run --args='-c python/ec2/log-validation.yml
          --testing-id ${{ env.TESTING_ID }}
          --endpoint http://${{ env.MAIN_SERVICE_ENDPOINT }}
          --remote-service-deployment-name ${{ env.REMOTE_SERVICE_IP }}:8001
          --region ${{ env.AWS_DEFAULT_REGION }}
          --account-id ${{ env.TEST_ACCOUNT }}
          --metric-namespace ${{ env.METRIC_NAMESPACE }}
          --log-group ${{ env.LOG_GROUP_NAME }}
          --service-name python-sample-application-${{ env.TESTING_ID }}
          --remote-service-name python-sample-remote-application-${{ env.TESTING_ID }}
          --request-body ip=${{ env.REMOTE_SERVICE_IP }}
          --instance-ami ${{ env.EC2_INSTANCE_AMI }}
          --rollup'

      - name: Validate generated metrics
        id: metric-validation
        if: (success() || steps.log-validation.outcome == 'failure') && !cancelled()
        run: ./gradlew validator:run --args='-c python/ec2/metric-validation.yml
          --testing-id ${{ env.TESTING_ID }}
          --endpoint http://${{ env.MAIN_SERVICE_ENDPOINT }}
          --remote-service-deployment-name ${{ env.REMOTE_SERVICE_IP }}:8001
          --region ${{ env.AWS_DEFAULT_REGION }}
          --account-id ${{ env.TEST_ACCOUNT }}
          --metric-namespace ${{ env.METRIC_NAMESPACE }}
          --log-group ${{ env.LOG_GROUP_NAME }}
          --service-name python-sample-application-${{ env.TESTING_ID }}
          --remote-service-name python-sample-remote-application-${{ env.TESTING_ID }}
          --request-body ip=${{ env.REMOTE_SERVICE_IP }}
          --instance-ami ${{ env.EC2_INSTANCE_AMI }}
          --rollup'

      - name: Validate generated traces
        id: trace-validation
        if: (success() || steps.log-validation.outcome == 'failure' || steps.metric-validation.outcome == 'failure') && !cancelled()
        run: ./gradlew validator:run --args='-c python/ec2/trace-validation.yml
          --testing-id ${{ env.TESTING_ID }}
          --endpoint http://${{ env.MAIN_SERVICE_ENDPOINT }}
          --remote-service-deployment-name ${{ env.REMOTE_SERVICE_IP }}:8001
          --region ${{ env.AWS_DEFAULT_REGION }}
          --account-id ${{ env.TEST_ACCOUNT }}
          --metric-namespace ${{ env.METRIC_NAMESPACE }}
          --log-group ${{ env.LOG_GROUP_NAME }}
          --service-name python-sample-application-${{ env.TESTING_ID }}
          --remote-service-name python-sample-remote-application-${{ env.TESTING_ID }}
          --request-body ip=${{ env.REMOTE_SERVICE_IP }}
          --instance-ami ${{ env.EC2_INSTANCE_AMI }}
          --rollup'

      - name: Publish metric on test result
        if: always()
        run: |
          if [[ "${{ steps.log-validation.outcome }}" == "success" && "${{ steps.metric-validation.outcome }}" == "success" && "${{ steps.trace-validation.outcome }}" == "success" ]]; then
            aws cloudwatch put-metric-data --namespace 'ADOT/GitHubActions' \
            --metric-name Failure \
            --dimensions repository=${{ github.repository }},branch=${{ github.ref_name }},workflow=${{ inputs.caller-workflow-name }} \
            --value 0.0 \
            --region ${{ env.AWS_DEFAULT_REGION }}
          else
            aws cloudwatch put-metric-data --namespace 'ADOT/GitHubActions' \
            --metric-name Failure \
            --dimensions repository=${{ github.repository }},branch=${{ github.ref_name }},workflow=${{ inputs.caller-workflow-name }} \
            --value 1.0 \
            --region ${{ env.AWS_DEFAULT_REGION }}
          fi

      # Clean up Procedures
      - name: Terraform destroy
        if: always()
        continue-on-error: true
        working-directory: terraform/python/ec2
        run: |
          terraform destroy -auto-approve \
            -var="test_id=${{ env.TESTING_ID }}"